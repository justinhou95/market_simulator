{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(\n",
    "    './data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=tran)\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    './data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=tran\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64         # number of data points in each batch\n",
    "N_EPOCHS = 10           # times to run the model on complete data\n",
    "INPUT_DIM = 28 * 28     # size of each input\n",
    "HIDDEN_DIM = 256        # hidden dimension   50\n",
    "LATENT_DIM = 75         # latent vector dimension   8\n",
    "N_CLASSES = 10          # number of classes in the data\n",
    "lr = 1e-3               # learning rate\n",
    "BETA = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx2onehot(idx, n=N_CLASSES):\n",
    "\n",
    "    assert idx.shape[1] == 1\n",
    "    assert torch.max(idx).item() < n\n",
    "\n",
    "    onehot = torch.zeros(idx.size(0), n)\n",
    "    onehot.scatter_(1, idx.data, 1)\n",
    "\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, condition_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim + condition_dim, hidden_dim)\n",
    "        self.mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.var = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.act = nn.LeakyReLU(0.3)\n",
    "    def forward(self, x):\n",
    "        hidden = self.act(self.linear(x))\n",
    "        mean = self.act(self.mu(hidden))\n",
    "        log_var = self.act(self.var(hidden))\n",
    "        return mean, log_var\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.latent_to_hidden = nn.Linear(latent_dim + n_classes, hidden_dim)\n",
    "        self.hidden_to_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.act = nn.LeakyReLU(0.3)\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.latent_to_hidden(x))\n",
    "        generated_x = torch.sigmoid(self.hidden_to_out(x))\n",
    "        return generated_x\n",
    "    \n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim, n_classes)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim, n_classes)\n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        z_mu, z_var = self.encoder(x)\n",
    "        std = torch.exp(z_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        x_sample = eps.mul(std).add_(z_mu)\n",
    "        z = torch.cat((x_sample, y), dim=1)\n",
    "        generated_x = self.decoder(z)\n",
    "        return generated_x, z_mu, z_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model = CVAE(INPUT_DIM, HIDDEN_DIM, LATENT_DIM, N_CLASSES)\n",
    "\n",
    "#optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(x, reconstructed_x, mean, log_var):\n",
    "    # reconstruction loss\n",
    "    RCL = F.binary_cross_entropy(reconstructed_x, x, size_average=False)\n",
    "    # kl divergence loss\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return (1 - BETA)* RCL + BETA*KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # set the train mode\n",
    "    model.train()\n",
    "    # loss of the epoch\n",
    "    train_loss = 0\n",
    "\n",
    "    for i, (x, y) in enumerate(train_iterator):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        y = idx2onehot(y.view(-1, 1))\n",
    "        optimizer.zero_grad()\n",
    "        reconstructed_x, z_mu, z_var = model(x, y)\n",
    "        loss = calculate_loss(x, reconstructed_x, z_mu, z_var)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    # set the evaluation mode\n",
    "    model.eval()\n",
    "    # test loss for the data\n",
    "    test_loss = 0\n",
    "    # we don't need to track the gradients, since we are not updating the parameters during evaluation / testing\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(test_iterator):\n",
    "            x = x.view(-1, 28 * 28)\n",
    "            y = idx2onehot(y.view(-1, 1))\n",
    "            reconstructed_x, z_mu, z_var = model(x, y)\n",
    "            loss = calculate_loss(x, reconstructed_x, z_mu, z_var)\n",
    "            test_loss += loss.item()\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\SongyanHou\\Programs\\Anaconda\\envs\\gpflow2\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 80.50, Test Loss: 65.16\n",
      "Epoch 1, Train Loss: 62.22, Test Loss: 59.45\n",
      "Epoch 2, Train Loss: 58.54, Test Loss: 56.94\n",
      "Epoch 3, Train Loss: 56.71, Test Loss: 55.61\n",
      "Epoch 4, Train Loss: 55.53, Test Loss: 54.67\n",
      "Epoch 5, Train Loss: 54.70, Test Loss: 53.88\n",
      "Epoch 6, Train Loss: 54.09, Test Loss: 53.60\n",
      "Epoch 7, Train Loss: 53.64, Test Loss: 52.99\n",
      "Epoch 8, Train Loss: 53.28, Test Loss: 52.72\n",
      "Epoch 9, Train Loss: 52.99, Test Loss: 52.43\n"
     ]
    }
   ],
   "source": [
    "best_test_loss = 1000\n",
    "for e in range(N_EPOCHS):\n",
    "\n",
    "    train_loss = train()\n",
    "    test_loss = test()\n",
    "\n",
    "    train_loss /= len(train_dataset)\n",
    "    test_loss /= len(test_dataset)\n",
    "\n",
    "    print(f'Epoch {e}, Train Loss: {train_loss:.2f}, Test Loss: {test_loss:.2f}')\n",
    "\n",
    "    if best_test_loss > test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        patience_counter = 1\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating a 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a random latent vector\n",
    "z = torch.randn(1, LATENT_DIM).to(device)\n",
    "\n",
    "# pick randomly 1 class, for which we want to generate the data\n",
    "y = torch.randint(0, N_CLASSES, (1, 1)).to(dtype=torch.long)\n",
    "print(f'Generating a {y.item()}')\n",
    "\n",
    "y = idx2onehot(y).to(device, dtype=z.dtype)\n",
    "z = torch.cat((z, y), dim=1)\n",
    "\n",
    "reconstructed_img = model.decoder(z)\n",
    "img = reconstructed_img.view(28, 28).data\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpflow2] *",
   "language": "python",
   "name": "conda-env-gpflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
