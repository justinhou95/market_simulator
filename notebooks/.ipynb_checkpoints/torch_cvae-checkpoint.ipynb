{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(\n",
    "    './data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=tran)\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    './data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=tran\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64         # number of data points in each batch\n",
    "N_EPOCHS = 10           # times to run the model on complete data\n",
    "INPUT_DIM = 28 * 28     # size of each input\n",
    "HIDDEN_DIM = 256        # hidden dimension   50\n",
    "LATENT_DIM = 75         # latent vector dimension   8\n",
    "N_CLASSES = 10          # number of classes in the data\n",
    "lr = 1e-3               # learning rate\n",
    "BETA = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx2onehot(idx, n=N_CLASSES):\n",
    "\n",
    "    assert idx.shape[1] == 1\n",
    "    assert torch.max(idx).item() < n\n",
    "\n",
    "    onehot = torch.zeros(idx.size(0), n)\n",
    "    onehot.scatter_(1, idx.data, 1)\n",
    "\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, condition_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim + condition_dim, hidden_dim)\n",
    "        self.mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.var = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.act = nn.LeakyReLU(0.3)\n",
    "    def forward(self, x):\n",
    "        hidden = self.act(self.linear(x))\n",
    "        mean = self.act(self.mu(hidden))\n",
    "        log_var = self.act(self.var(hidden))\n",
    "        return mean, log_var\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.latent_to_hidden = nn.Linear(latent_dim + n_classes, hidden_dim)\n",
    "        self.hidden_to_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.act = nn.LeakyReLU(0.3)\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.latent_to_hidden(x))\n",
    "        generated_x = torch.sigmoid(self.hidden_to_out(x))\n",
    "        return generated_x\n",
    "    \n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim, n_classes)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim, n_classes)\n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        z_mu, z_var = self.encoder(x)\n",
    "        std = torch.exp(z_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        x_sample = eps.mul(std).add_(z_mu)\n",
    "        z = torch.cat((x_sample, y), dim=1)\n",
    "        generated_x = self.decoder(z)\n",
    "        return generated_x, z_mu, z_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model = CVAE(INPUT_DIM, HIDDEN_DIM, LATENT_DIM, N_CLASSES)\n",
    "\n",
    "#optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(x, reconstructed_x, mean, log_var):\n",
    "    # reconstruction loss\n",
    "    RCL = F.binary_cross_entropy(reconstructed_x, x, size_average=False)\n",
    "    # kl divergence loss\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return (1 - BETA)* RCL + BETA*KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(train_iterator):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # set the train mode\n",
    "    model.train()\n",
    "\n",
    "    # loss of the epoch\n",
    "    train_loss = 0\n",
    "\n",
    "    for i, (x, y) in enumerate(train_iterator):\n",
    "        # reshape the data into [batch_size, 784]\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = x.to(device)\n",
    "\n",
    "        # convert y into one-hot encoding\n",
    "        y = idx2onehot(y.view(-1, 1))\n",
    "        y = y.to(device)\n",
    "\n",
    "        # update the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        reconstructed_x, z_mu, z_var = model(x, y)\n",
    "\n",
    "        # loss\n",
    "        loss = calculate_loss(x, reconstructed_x, z_mu, z_var)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    # set the evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # test loss for the data\n",
    "    test_loss = 0\n",
    "\n",
    "    # we don't need to track the gradients, since we are not updating the parameters during evaluation / testing\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(test_iterator):\n",
    "            # reshape the data\n",
    "            x = x.view(-1, 28 * 28)\n",
    "            x = x.to(device)\n",
    "\n",
    "            # convert y into one-hot encoding\n",
    "            y = idx2onehot(y.view(-1, 1))\n",
    "            y = y.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            reconstructed_x, z_mu, z_var = model(x, y)\n",
    "\n",
    "            # loss\n",
    "            loss = calculate_loss(x, reconstructed_x, z_mu, z_var)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\SongyanHou\\Programs\\Anaconda\\envs\\gpflow2\\lib\\site-packages\\torch\\nn\\functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "C:\\SongyanHou\\Programs\\Anaconda\\envs\\gpflow2\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 159.93, Test Loss: 128.86\n",
      "Epoch 1, Train Loss: 121.68, Test Loss: 114.92\n",
      "Epoch 2, Train Loss: 113.06, Test Loss: 109.97\n",
      "Epoch 3, Train Loss: 109.35, Test Loss: 107.73\n",
      "Epoch 4, Train Loss: 107.33, Test Loss: 105.75\n",
      "Epoch 5, Train Loss: 106.03, Test Loss: 104.77\n",
      "Epoch 6, Train Loss: 105.06, Test Loss: 104.04\n",
      "Epoch 7, Train Loss: 104.34, Test Loss: 103.33\n",
      "Epoch 8, Train Loss: 103.76, Test Loss: 103.08\n",
      "Epoch 9, Train Loss: 103.31, Test Loss: 102.56\n"
     ]
    }
   ],
   "source": [
    "best_test_loss = 1000\n",
    "for e in range(N_EPOCHS):\n",
    "\n",
    "    train_loss = train()\n",
    "    test_loss = test()\n",
    "\n",
    "    train_loss /= len(train_dataset)\n",
    "    test_loss /= len(test_dataset)\n",
    "\n",
    "    print(f'Epoch {e}, Train Loss: {train_loss:.2f}, Test Loss: {test_loss:.2f}')\n",
    "\n",
    "    if best_test_loss > test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        patience_counter = 1\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating a 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a random latent vector\n",
    "z = torch.randn(1, LATENT_DIM).to(device)\n",
    "\n",
    "# pick randomly 1 class, for which we want to generate the data\n",
    "y = torch.randint(0, N_CLASSES, (1, 1)).to(dtype=torch.long)\n",
    "print(f'Generating a {y.item()}')\n",
    "\n",
    "y = idx2onehot(y).to(device, dtype=z.dtype)\n",
    "z = torch.cat((z, y), dim=1)\n",
    "\n",
    "reconstructed_img = model.decoder(z)\n",
    "img = reconstructed_img.view(28, 28).data\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpflow2] *",
   "language": "python",
   "name": "conda-env-gpflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
